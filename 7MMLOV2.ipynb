{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec4db934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found device type: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers.optimization import get_linear_schedule_with_warmup\n",
    "import pandas as pd\n",
    "import os\n",
    "import html\n",
    "import re\n",
    "\n",
    "BASE_PATH = os.getcwd() + \"/Data\"\n",
    "\n",
    "BEST_MODEL_PATH = \"%s\\\\best_model.pt\" % (BASE_PATH)\n",
    "\n",
    "ALL_FILE_PATH = BASE_PATH + \"/all.txt\"\n",
    "COSINE_SCORE_PATH = BASE_PATH + \"/cosine_similarity.csv\"\n",
    "\n",
    "TRAIN_FILE_SRC_ORIG = BASE_PATH + \"/wiki.full.aner.ori.train.src\"\n",
    "TRAIN_FILE_DST_ORIG = BASE_PATH + \"/wiki.full.aner.ori.train.dst\"\n",
    "VALID_FILE_DST_ORIG = BASE_PATH + \"/wiki.full.aner.ori.valid.dst\"\n",
    "VALID_FILE_SRC_ORIG = BASE_PATH + \"/wiki.full.aner.ori.valid.src\"\n",
    "TEST_FILE_DST_ORIG = BASE_PATH + \"/wiki.full.aner.ori.test.dst\"\n",
    "TEST_FILE_SRC_ORIG = BASE_PATH + \"/wiki.full.aner.ori.test.src\"\n",
    "TRAIN_FILE_SRC = BASE_PATH + \"/train.src\"\n",
    "TRAIN_FILE_DST = BASE_PATH + \"/train.dst\"\n",
    "VALID_FILE_DST = BASE_PATH + \"/valid.dst\"\n",
    "VALID_FILE_SRC = BASE_PATH + \"/valid.src\"\n",
    "TEST_FILE_DST = BASE_PATH + \"/test.dst\"\n",
    "TEST_FILE_SRC = BASE_PATH + \"/test.src\"\n",
    "\n",
    "SPM_MODEL_PATH = BASE_PATH + \"/spm.model\"\n",
    "SPM_VOCAB_PATH = BASE_PATH + \"/spm.vocab\"\n",
    "\n",
    "MAX_LENGTH = 126\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Found device type: {DEVICE}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d79d8a",
   "metadata": {},
   "source": [
    "**Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b770e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_line(line):\n",
    "    # Převede HTML entity na jejich znaky (např. &ndash; → –)\n",
    "    s = html.unescape(line)\n",
    "    \n",
    "    # Nahrazení -LRB-/-RRB- závorkami\n",
    "    s = s.replace(\"-LRB-\", \"(\").replace(\"-RRB-\", \")\")\n",
    "    \n",
    "    # Odstranění závorek s nesmyslným obsahem (např. \"( , ; , ; )\")\n",
    "    s = re.sub(r'\\(\\s*[,;:.!? ]+\\s*\\)', '', s)        \n",
    "    s = s.lower()\n",
    "    s = re.sub(r\"[^a-z0-9 .!?]\", \"\", s)\n",
    "    s = s.strip() + \"\\n\"\n",
    "    return s\n",
    "\n",
    "if not os.path.isfile(ALL_FILE_PATH):\n",
    "    with open(TRAIN_FILE_SRC_ORIG, \"r\", encoding=\"utf-8\") as file:\n",
    "        lines = [clean_line(line.strip()) for line in file.readlines()]\n",
    "        all_lines = lines\n",
    "        file.close()\n",
    "    with open(TRAIN_FILE_SRC, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.writelines(lines)\n",
    "        file.close()\n",
    "        \n",
    "    with open(TRAIN_FILE_DST_ORIG, \"r\", encoding=\"utf-8\") as file:\n",
    "        lines = [clean_line(line.strip()) for line in file.readlines()]\n",
    "        all_lines += lines\n",
    "        file.close()\n",
    "    with open(TRAIN_FILE_DST, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.writelines(lines)\n",
    "        file.close()\n",
    "        \n",
    "    with open(VALID_FILE_SRC_ORIG, \"r\", encoding=\"utf-8\") as file:\n",
    "        lines = [clean_line(line.strip()) for line in file.readlines()]\n",
    "        all_lines += lines\n",
    "        file.close()\n",
    "    with open(VALID_FILE_SRC, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.writelines(lines)\n",
    "        file.close()\n",
    "\n",
    "    with open(VALID_FILE_DST_ORIG, \"r\", encoding=\"utf-8\") as file:\n",
    "        lines = [clean_line(line.strip()) for line in file.readlines()]\n",
    "        all_lines += lines\n",
    "        file.close()\n",
    "    with open(VALID_FILE_DST, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.writelines(lines)\n",
    "        file.close()\n",
    "\n",
    "    with open(TEST_FILE_DST_ORIG, \"r\", encoding=\"utf-8\") as file:\n",
    "        lines = [clean_line(line.strip()) for line in file.readlines()]\n",
    "        all_lines += lines\n",
    "        file.close()\n",
    "    with open(TEST_FILE_DST, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.writelines(lines)\n",
    "        file.close()\n",
    "\n",
    "    with open(TEST_FILE_SRC_ORIG, \"r\", encoding=\"utf-8\") as file:\n",
    "        lines = [clean_line(line.strip()) for line in file.readlines()]\n",
    "        all_lines += lines\n",
    "        file.close()\n",
    "    with open(TEST_FILE_SRC, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.writelines(lines)\n",
    "        file.close()\n",
    "\n",
    "    with open(ALL_FILE_PATH, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.writelines(all_lines)\n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4262b007",
   "metadata": {},
   "source": [
    "**Analýza datasetu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "850294a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg of cosine similarity: 0.7100\n",
      "Mean of cosine similarity: 0.7100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "from statistics import mean\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "cosine_scores = []\n",
    "\n",
    "if not os.path.isfile(COSINE_SCORE_PATH):\n",
    "    st_model = SentenceTransformer('all-MiniLM-L6-v2', device=DEVICE.type)\n",
    "\n",
    "    sentences_complex = open(TRAIN_FILE_SRC, encoding=\"utf-8\").read().strip().split('\\n')\n",
    "    sentences_simple = open(TRAIN_FILE_DST, encoding=\"utf-8\").read().strip().split('\\n')\n",
    "\n",
    "    \n",
    "    for i, (c, s) in enumerate(zip(sentences_complex, sentences_simple)):\n",
    "        emb_complex = st_model.encode(c, convert_to_tensor=True, batch_size=1)\n",
    "        emb_simple = st_model.encode(s, convert_to_tensor=True, batch_size=1)\n",
    "        score = torch.nn.functional.cosine_similarity(emb_complex.unsqueeze(0), emb_simple.unsqueeze(0))\n",
    "        cosine_scores.append(score.item())\n",
    "        # print(f\"Pair {i+1}:\")\n",
    "        # print(f\"  Complex: {c}\")\n",
    "        # print(f\"  Simple:  {s}\")\n",
    "        # print(f\"  Cosine similarity: {score.item():.4f}\\n\")\n",
    "    \n",
    "    with open(COSINE_SCORE_PATH, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.writelines([f\"{score}\\n\" for score in cosine_scores])\n",
    "else:\n",
    "    with open(COSINE_SCORE_PATH, encoding=\"utf-8\") as file:\n",
    "        cosine_scores = [float(score) for score in file.read().strip().split('\\n')]\n",
    "    # df = pd.read_csv(COSINE_SCORE_PATH)\n",
    "    # cosine_scores = df[0].tolist()\n",
    "    print(\"Cosine similarity scores loaded from file.\\n\")        \n",
    "\n",
    "print(f\"Avg of cosine similarity: {sum(cosine_scores) / len(cosine_scores):.4f}\")\n",
    "print(f\"Mean of cosine similarity: {mean(cosine_scores):.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20435ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.DataFrame(cosine_scores, columns=[\"cosine_similarity\"])\n",
    "df.to_csv(\"cosine_similarity.csv\", index=False)\n",
    "data = cosine_scores\n",
    "\n",
    "plt.hist(data, bins=30, color='skyblue', edgecolor='black')\n",
    "plt.title('Histogram')\n",
    "plt.xlabel('Hodnota')\n",
    "plt.ylabel('Frekvence')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb32251",
   "metadata": {},
   "source": [
    "**Použití SentencePieces tokenizeru**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "75b0d1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "if not os.path.isfile(SPM_MODEL_PATH) or not os.path.isfile(SPM_VOCAB_PATH):\n",
    "    spm.SentencePieceTrainer.Train(\n",
    "        input=ALL_FILE_PATH,\n",
    "        model_prefix=\"Data/spm\",\n",
    "        vocab_size=24000,\n",
    "        character_coverage=1.0\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86e093c",
   "metadata": {},
   "source": [
    "**Maximalni delka tensoru**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6705166a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length: 126\n"
     ]
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.LoadFromFile(SPM_MODEL_PATH)\n",
    "\n",
    "\n",
    "if MAX_LENGTH == 0:\n",
    "    with open(ALL_FILE_PATH, \"r\", encoding=\"utf-8\") as file:\n",
    "        lengths = []\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            piece = sp.EncodeAsPieces(line)\n",
    "            lengths.append(len(piece))\n",
    "\n",
    "        MAX_LENGTH = max(lengths) + 2\n",
    "\n",
    "print(f\"Max length: {MAX_LENGTH}\") # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5de76374",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplificationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, src_lines, tgt_lines, sp_model, batch_size, shuffle, max_len=50):\n",
    "        self.sp = sp_model\n",
    "        self.src_lines = src_lines\n",
    "        self.tgt_lines = tgt_lines\n",
    "        self.max_len = max_len\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src_lines)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            src = self.sp.encode(self.src_lines[idx], out_type=int)\n",
    "            tgt = self.sp.encode(self.tgt_lines[idx], out_type=int)\n",
    "        except Exception as e:\n",
    "            print(f\"Error encoding line {idx}: {e}\")\n",
    "            return\n",
    "\n",
    "        src = src[:self.max_len]\n",
    "        tgt = tgt[:self.max_len]\n",
    "\n",
    "        src += [0] * (self.max_len - len(src))\n",
    "        tgt += [0] * (self.max_len - len(tgt))\n",
    "\n",
    "        return {\n",
    "            'src': torch.tensor([self.sp.bos_id()] + src + [self.sp.eos_id()], dtype=torch.long),\n",
    "            'tgt': torch.tensor([self.sp.bos_id()] + tgt + [self.sp.eos_id()], dtype=torch.long),\n",
    "        }\n",
    "    \n",
    "    def get_data_loader(self):\n",
    "        return torch.utils.data.DataLoader(self, self.batch_size, self.shuffle)\n",
    "\n",
    "    \n",
    "class SimplificationDatasetFactory:\n",
    "    def __init__(self, sp_model, src_path, tgt_path, batch_size, shuffle, cosine_scores_path=None, max_items=0, max_len=50) -> None:\n",
    "        self._src_path = src_path\n",
    "        self._tgt_path = tgt_path\n",
    "        self._max_items = max_items\n",
    "        self._max_len = max_len\n",
    "        self._sp_model = sp_model\n",
    "        self._batch_size = batch_size\n",
    "        self._shuffle = shuffle\n",
    "\n",
    "        self._src_lines = open(src_path, encoding=\"utf-8\").read().strip().split('\\n')\n",
    "        self._tgt_lines = open(tgt_path, encoding=\"utf-8\").read().strip().split('\\n')\n",
    "        if cosine_scores_path is not None:\n",
    "            cosine_scores = open(cosine_scores_path, encoding=\"utf-8\").read().strip().split('\\n')\n",
    "            self._cosine_scores = [float(x) for x in cosine_scores]\n",
    "\n",
    "    def create(self, min_cosine_score=None):\n",
    "        if min_cosine_score is None or self._cosine_scores is None:\n",
    "            src_lines = self._src_lines\n",
    "            tgt_lines = self._tgt_lines\n",
    "        else:\n",
    "            src_lines = []\n",
    "            tgt_lines = []\n",
    "            for i, (src, tgt) in enumerate(zip(self._src_lines, self._tgt_lines)):\n",
    "                if self._cosine_scores[i] <= min_cosine_score:\n",
    "                    src_lines.append(src)\n",
    "                    tgt_lines.append(tgt)\n",
    "\n",
    "        return SimplificationDataset(src_lines, tgt_lines, self._sp_model, self._batch_size, self._shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999bf7ab",
   "metadata": {},
   "source": [
    "**Encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "db20e7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, hidden_dim, num_layers=1, dropout = 0.3):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, emb_dim)        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=emb_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        emb = self.embed(x)\n",
    "        _, (h, c) = self.lstm(emb)\n",
    "        return _, h, c\n",
    "    \n",
    "class EncoderWithAttention(Encoder):\n",
    "    def forward(self, x):\n",
    "        emb = self.embed(x)\n",
    "        o, (h, c) = self.lstm(emb)\n",
    "        return o, h, c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c0cbaf",
   "metadata": {},
   "source": [
    "**Decoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "94a73ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, hidden_dim, num_layers=1, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.lstm = nn.LSTM(            \n",
    "            input_size=emb_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x, h, c):\n",
    "        emb = self.embed(x.unsqueeze(1))\n",
    "        output, (h, c) = self.lstm(emb, (h, c))\n",
    "        logits = self.fc(output.squeeze(1))\n",
    "        return logits, h, c\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        # obvykle vezmeme poslední vrstvu a první směr, např. hidden[-1]\n",
    "        # proto pro jednoduchost počítáme jen s posledním hidden state:\n",
    "        #   vybereme hidden[-1]\n",
    "        hidden = hidden[-1]\n",
    "        \n",
    "        # Spočítat skóre (batch, seq_len)\n",
    "        attn_scores = torch.bmm(encoder_outputs, hidden.unsqueeze(2)).squeeze(2)\n",
    "        \n",
    "        # Softmax přes seq_len dimenzi\n",
    "        attn_weights = F.softmax(attn_scores, dim=1)\n",
    "        \n",
    "        # Vážený součet encoder outputs\n",
    "        context = torch.bmm(attn_weights.unsqueeze(1), encoder_outputs).squeeze(1)\n",
    "        \n",
    "        return context, attn_weights\n",
    "\n",
    "    \n",
    "class DecoderWithAttention(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, hidden_dim, num_layers=1, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=emb_dim + hidden_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "        self.attention = Attention(hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, vocab_size)\n",
    "\n",
    "    def forward(self, input_token, hidden, cell, encoder_outputs):\n",
    "        embedded = self.embedding(input_token).unsqueeze(1)\n",
    "        context, attn_weights = self.attention(hidden, encoder_outputs)\n",
    "\n",
    "        # Spojení embedding a contextu\n",
    "        rnn_input = torch.cat((embedded, context.unsqueeze(1)), dim=2)\n",
    "\n",
    "        # LSTM krok\n",
    "        output, (hidden, cell) = self.lstm(rnn_input, (hidden, cell))\n",
    "\n",
    "        output = output.squeeze(1)\n",
    "        output = torch.cat((output, context), dim=1)\n",
    "\n",
    "        output = self.fc(output)\n",
    "        return output, hidden, cell, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a391b49",
   "metadata": {},
   "source": [
    "**Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b6cccbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self._encoder = encoder\n",
    "        self._decoder = decoder\n",
    "        self._device = device\n",
    "\n",
    "    @property \n",
    "    def encoder(self):\n",
    "        return self._encoder\n",
    "    \n",
    "    @property \n",
    "    def decoder(self):\n",
    "        return self._decoder\n",
    "    \n",
    "    @property \n",
    "    def device(self):\n",
    "        return self._device\n",
    "\n",
    "    def forward(self, src, tgt, teacher_forcing_ratio=0.5):\n",
    "        batch_size, tgt_len = tgt.size()\n",
    "        vocab_size = self._decoder.fc.out_features\n",
    "        outputs = torch.zeros(batch_size, tgt_len, vocab_size).to(self._device)\n",
    "\n",
    "        h, c = self._encoder(src)\n",
    "        input = tgt[:, 0]  # <sos>\n",
    "\n",
    "        for t in range(1, tgt_len):\n",
    "            output, h, c = self._decoder(input, h, c)\n",
    "            outputs[:, t] = output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)\n",
    "            input = tgt[:, t] if teacher_force else top1\n",
    "\n",
    "        return outputs\n",
    "    \n",
    "class Seq2SeqWithAttention(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self._encoder = encoder\n",
    "        self._decoder = decoder\n",
    "        self._device = device\n",
    "\n",
    "    @property \n",
    "    def encoder(self):\n",
    "        return self._encoder\n",
    "    \n",
    "    @property \n",
    "    def decoder(self):\n",
    "        return self._decoder\n",
    "    \n",
    "    @property \n",
    "    def device(self):\n",
    "        return self._device\n",
    "\n",
    "    def forward(self, src, tgt, teacher_forcing_ratio=0.5):\n",
    "        # batch_size, tgt_len = tgt.shape\n",
    "        # vocab_size = self._decoder.fc.out_features\n",
    "        batch_size = src.size(0)\n",
    "        tgt_len = tgt.size(1)\n",
    "        vocab_size = self._decoder.fc.out_features\n",
    "        outputs = torch.zeros(batch_size, tgt_len, vocab_size).to(self._device)\n",
    "\n",
    "        encoder_outputs, h, c = self._encoder(src)\n",
    "        \n",
    "        input = tgt[:, 0]  # <sos>\n",
    "\n",
    "        for t in range(1, tgt_len):\n",
    "            output, h, c, _ = self._decoder(input, h, c, encoder_outputs)\n",
    "            outputs[:, t] = output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)\n",
    "            input = tgt[:, t] if teacher_force else top1\n",
    "\n",
    "        return outputs\n",
    "    \n",
    "    def inference(self, src, max_len=50, sos_token=1, eos_token=2):\n",
    "        self.eval()\n",
    "        batch_size = src.size(0)\n",
    "        vocab_size = self.decoder.fc.out_features\n",
    "\n",
    "        outputs = torch.zeros(batch_size, max_len, dtype=torch.long).to(self.device)\n",
    "        logits = torch.zeros(batch_size, max_len, vocab_size).to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            encoder_outputs, (hidden, cell) = self.encoder(src)\n",
    "            input_token = torch.LongTensor([sos_token] * batch_size).to(self.device)\n",
    "\n",
    "            for t in range(max_len):\n",
    "                output, hidden, cell, _ = self.decoder(input_token, hidden, cell, encoder_outputs)\n",
    "                logit = output\n",
    "                input_token = output.argmax(1)\n",
    "\n",
    "                outputs[:, t] = input_token\n",
    "                logits[:, t, :] = logit\n",
    "\n",
    "                if (input_token == eos_token).all():\n",
    "                    break\n",
    "\n",
    "        return outputs, logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7425871",
   "metadata": {},
   "source": [
    "**Tréning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8935d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5):\n",
    "        self._patience = patience\n",
    "        self._best_loss = 0.0000\n",
    "        self._epochs_no_improve = 0\n",
    "        self._stop = False\n",
    "        \n",
    "    def __call__(self, valid_loss):\n",
    "        if valid_loss < self._best_loss:\n",
    "            self._best_loss = valid_loss\n",
    "            self._epochs_no_improve = 0\n",
    "        else:\n",
    "            self._epochs_no_improve += 1\n",
    "            if self._epochs_no_improve >= self._patience:\n",
    "                self._stop = True\n",
    "        return self._stop\n",
    "    \n",
    "    def reset(self):\n",
    "        self._best_loss = 0.0000\n",
    "        self._epochs_no_improve = 0\n",
    "        self._stop = False\n",
    "\n",
    "class Train:\n",
    "    def __init__(self, model, train_dataset_factory, valid_dataset, optimizer,criterion, device, path, scheduler=None, patience=5):\n",
    "        self._model = model\n",
    "        self._train_dataset_factory = train_dataset_factory\n",
    "        self._valid_dataset = valid_dataset\n",
    "        self._optimizer = optimizer\n",
    "        self._criterion = criterion\n",
    "        self._device = device\n",
    "        self._path = path\n",
    "        self._scheduler = scheduler\n",
    "        self._early_stopping = EarlyStopping(patience=patience)\n",
    "        self._train_data_loader = None\n",
    "        \n",
    "    def run(self, epochs):\n",
    "        self._init_run()\n",
    "        self._run_epochs(epochs)\n",
    "    \n",
    "    def _init_run(self):        \n",
    "        self._model.train()\n",
    "        self._total_loss = 0\n",
    "        self._early_stopping.reset()\n",
    "        self._train_data_loader = None\n",
    "\n",
    "    def _set_train_dataloader(self, epoch):\n",
    "        if self._train_data_loader is None:\n",
    "            dataset = self._train_dataset_factory.create(max_cosine_score=None)\n",
    "            self._train_data_loader = dataset.get_data_loader()\n",
    "            return True\n",
    "\n",
    "    def _run_epochs(self, epochs):\n",
    "        best_loss = 0.0000\n",
    "        best_epoch = 0\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            start_time = time.time()\n",
    "            dataset_changed = self._set_train_dataloader(epoch)\n",
    "            train_loss = self._epoch()            \n",
    "            valid_loss = self._validate()\n",
    "            end_time = time.time()\n",
    "            duration = end_time - start_time            \n",
    "            print(f\"Epoch {epoch} duration {timedelta(seconds=int(duration))}:\")\n",
    "            print(f\"\\tTrain loss: {train_loss:.4f} \\tValid loss: {valid_loss:.4f}\")\n",
    "\n",
    "            if valid_loss < best_loss or epoch == 0:\n",
    "                best_loss = valid_loss\n",
    "                best_epoch = epoch\n",
    "                torch.save(self._model.state_dict(), self._get_filename())\n",
    "                \n",
    "            if dataset_changed:\n",
    "                self._dataset_changed(epoch)\n",
    "            \n",
    "            if self._early_stopping(valid_loss):\n",
    "                print(f\"Early stopping at epoch {epoch}\")\n",
    "                break\n",
    "\n",
    "        print(f\"Finished with epoch {best_epoch} with validation loss {best_loss:.4f}\")\n",
    "\n",
    "        self._model.load_state_dict(torch.load(self._get_filename(), weights_only=True))\n",
    "    \n",
    "    def _dataset_changed(self, epoch):\n",
    "        pass\n",
    "        \n",
    "    def _epoch(self):\n",
    "        total_loss = 0.0000\n",
    "        \n",
    "        try:\n",
    "            for batch in self._train_data_loader: # type: ignore\n",
    "                src, tgt = batch[\"src\"].to(self._device), batch[\"tgt\"].to(self._device)\n",
    "                self._optimizer.zero_grad()\n",
    "                \n",
    "                output = self._model(src, tgt)\n",
    "                output = output[:, 1:].reshape(-1, output.size(-1))\n",
    "                tgt = tgt[:, 1:].reshape(-1)\n",
    "                \n",
    "                loss = self._criterion(output, tgt)\n",
    "                loss.backward()\n",
    "                self._optimizer.step()\n",
    "                if self._scheduler is not None:\n",
    "                    self._scheduler.step()\n",
    "                total_loss += loss.item()\n",
    "            return total_loss / len(self._train_data_loader) # type: ignore\n",
    "        except Exception as e:\n",
    "            print(f\"Error during training: {e}\")\n",
    "    \n",
    "    def _validate(self):\n",
    "        self._model.eval()\n",
    "        total_loss = 0.0000\n",
    "        data_loader = self._valid_dataset.get_data_loader()\n",
    "        with torch.no_grad():\n",
    "            for batch in data_loader:\n",
    "                src, tgt = batch[\"src\"].to(self._device), batch[\"tgt\"].to(self._device)\n",
    "                output = self._model(src, tgt)\n",
    "                output = output[:, 1:].reshape(-1, output.size(-1))\n",
    "                tgt = tgt[:, 1:].reshape(-1)\n",
    "                loss = self._criterion(output, tgt)\n",
    "                total_loss += loss.item()\n",
    "        self._model.train()\n",
    "        return total_loss / len(data_loader)\n",
    "    \n",
    "    def _get_filename(self):\n",
    "        return \"%s\\\\best_model.pt\" % (self._path)\n",
    "    \n",
    "class TrainWithCurriculumLearning(Train):\n",
    "    def __init__(self, model, train_dataset_factory, valid_dataset, optimizer, criterion, device, path, easy_koef=0.1, medium_koef=0.4, easy_cosine_score=0.85, medium_cosine_score=0.6, scheduler=None):\n",
    "        super().__init__(model, train_dataset_factory, valid_dataset, optimizer, criterion, device, path, scheduler)\n",
    "        self._easy_koef = easy_koef\n",
    "        self._medium_koef = medium_koef\n",
    "        self._easy_cosine_score = easy_cosine_score\n",
    "        self._medium_cosine_score = medium_cosine_score\n",
    "        \n",
    "    def _run_epochs(self, epochs):\n",
    "        self._split_cosine_score(epochs)\n",
    "        super()._run_epochs(epochs)    \n",
    "    \n",
    "    def _dataset_changed(self, epoch):\n",
    "        cosine_score = self._get_cosine_score(epoch)\n",
    "        print (f\"Dataset changed at epoch {epoch} for cosine score < {cosine_score} \")\n",
    "        filename = \"{self._path}\\\\model_epoch_{epoch}_and cosine score < {cosine_score}.pt\"         \n",
    "        torch.save(self._model.state_dict(), filename)\n",
    "        \n",
    "    def set_train_dataloader(self, epoch):\n",
    "        if epoch in self._epochs_split:\n",
    "            self._train_data_loader = None\n",
    "            \n",
    "        if self._train_data_loader is None:\n",
    "            dataset = self._train_dataset_factory.create(\n",
    "                min_cosine_score=self._get_cosine_score(epoch)\n",
    "            )\n",
    "            self._train_data_loader = dataset.get_data_loader()\n",
    "            return True\n",
    "\n",
    "    def _split_cosine_score(self, epochs):\n",
    "        self._epochs_split = [round(epochs * self._easy_koef), round(epochs * self._medium_koef)]\n",
    "    \n",
    "    def _get_cosine_score(self, epoch):\n",
    "        if epoch < self._epochs_split[0]:\n",
    "            return self._easy_cosine_score\n",
    "        elif epoch < self._epochs_split[1]:\n",
    "            return self._medium_cosine_score\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9c18fb00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 duration 0:12:40:\n",
      "\tTrain loss: 5.9907 \tValid loss: 5.7203\n",
      "Epoch 1 duration 0:12:45:\n",
      "\tTrain loss: 5.4674 \tValid loss: 5.4442\n",
      "Epoch 2 duration 0:12:37:\n",
      "\tTrain loss: 5.2140 \tValid loss: 5.4102\n",
      "Epoch 3 duration 0:12:29:\n",
      "\tTrain loss: 5.0316 \tValid loss: 5.3541\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 62\u001b[0m\n\u001b[0;32m     49\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     51\u001b[0m training \u001b[38;5;241m=\u001b[39m TrainWithCurriculumLearning(\n\u001b[0;32m     52\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     53\u001b[0m     train_dataset_factory\u001b[38;5;241m=\u001b[39mtrain_dataset_factory,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     60\u001b[0m     medium_koef\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m,\n\u001b[0;32m     61\u001b[0m )\n\u001b[1;32m---> 62\u001b[0m \u001b[43mtraining\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[51], line 41\u001b[0m, in \u001b[0;36mTrain.run\u001b[1;34m(self, epochs)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, epochs):\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_run()\n\u001b[1;32m---> 41\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_epochs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[51], line 131\u001b[0m, in \u001b[0;36mTrainWithCurriculumLearning._run_epochs\u001b[1;34m(self, epochs)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_epochs\u001b[39m(\u001b[38;5;28mself\u001b[39m, epochs):\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_cosine_score(epochs)\n\u001b[1;32m--> 131\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_epochs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[51], line 61\u001b[0m, in \u001b[0;36mTrain._run_epochs\u001b[1;34m(self, epochs)\u001b[0m\n\u001b[0;32m     59\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_train_dataloader(epoch)\n\u001b[1;32m---> 61\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m            \n\u001b[0;32m     62\u001b[0m valid_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate()\n\u001b[0;32m     63\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "Cell \u001b[1;32mIn[51], line 94\u001b[0m, in \u001b[0;36mTrain._epoch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     91\u001b[0m tgt \u001b[38;5;241m=\u001b[39m tgt[:, \u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     93\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_criterion(output, tgt)\n\u001b[1;32m---> 94\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_scheduler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Michal\\tmp\\7LLMO\\.7LLMO310\\lib\\site-packages\\torch\\_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    647\u001b[0m     )\n\u001b[1;32m--> 648\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Michal\\tmp\\7LLMO\\.7LLMO310\\lib\\site-packages\\torch\\autograd\\__init__.py:353\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    348\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    350\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 353\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Michal\\tmp\\7LLMO\\.7LLMO310\\lib\\site-packages\\torch\\autograd\\graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    822\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    825\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    826\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.LoadFromFile(SPM_MODEL_PATH)\n",
    "\n",
    "EMB_DIM = 256 #512 #128\n",
    "HIDDEN_DIM = 512 #256 #64\n",
    "\n",
    "encoder = EncoderWithAttention(\n",
    "    vocab_size=sp.GetPieceSize(),\n",
    "    emb_dim=EMB_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    num_layers=2\n",
    ")\n",
    "\n",
    "decoder = DecoderWithAttention(\n",
    "    vocab_size=sp.GetPieceSize(),\n",
    "    emb_dim=EMB_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    num_layers=2\n",
    ")\n",
    "\n",
    "MAX_ITEMS = 0\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "train_dataset_factory = SimplificationDatasetFactory(\n",
    "    sp_model=sp,\n",
    "    src_path=TRAIN_FILE_SRC,\n",
    "    tgt_path=TRAIN_FILE_DST,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    max_len=MAX_LENGTH,\n",
    "    cosine_scores_path=COSINE_SCORE_PATH\n",
    ")\n",
    "\n",
    "valid_dataset = SimplificationDatasetFactory(\n",
    "    sp_model=sp, src_path=VALID_FILE_SRC, tgt_path=VALID_FILE_DST, batch_size=BATCH_SIZE, shuffle=False\n",
    ").create()\n",
    "valid_loader = valid_dataset.get_data_loader()\n",
    "\n",
    "model = Seq2SeqWithAttention(encoder, decoder, DEVICE).to(DEVICE)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "# scheduler = get_linear_schedule_with_warmup(\n",
    "#     optimizer,\n",
    "#     num_warmup_steps=0,\n",
    "#     num_training_steps=len(train_loader) * EPOCHS\n",
    "# )\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "training = TrainWithCurriculumLearning(\n",
    "    model=model,\n",
    "    train_dataset_factory=train_dataset_factory,\n",
    "    valid_dataset=valid_dataset,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    device=DEVICE,\n",
    "    path=BASE_PATH,\n",
    "    easy_koef=0.6,\n",
    "    medium_koef=0.3,\n",
    ")\n",
    "training.run(epochs=EPOCHS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".7LLMO310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
